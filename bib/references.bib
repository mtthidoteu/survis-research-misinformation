
@article{phan_fake_2023,
	title = {Fake news detection: {A} survey of graph neural network methods},
	volume = {139},
	issn = {1568-4946},
	shorttitle = {Fake news detection},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10036155/},
	doi = {10.1016/j.asoc.2023.110235},
	abstract = {The emergence of various social networks has generated vast volumes of data. Efficient methods for capturing, distinguishing, and filtering real and fake news are becoming increasingly important, especially after the outbreak of the COVID-19 pandemic. This study conducts a multiaspect and systematic review of the current state and challenges of graph neural networks (GNNs) for fake news detection systems and outlines a comprehensive approach to implementing fake news detection systems using GNNs. Furthermore, advanced GNN-based techniques for implementing pragmatic fake news detection systems are discussed from multiple perspectives. First, we introduce the background and overview related to fake news, fake news detection, and GNNs. Second, we provide a GNN taxonomy-based fake news detection taxonomy and review and highlight models in categories. Subsequently, we compare critical ideas, advantages, and disadvantages of the methods in categories. Next, we discuss the possible challenges of fake news detection and GNNs. Finally, we present several open issues in this area and discuss potential directions for future research. We believe that this review can be utilized by systems practitioners and newcomers in surmounting current impediments and navigating future situations by deploying a fake news detection system using GNNs.},
	urldate = {2024-05-15},
	journal = {Applied Soft Computing},
	author = {Phan, Huyen Trang and Nguyen, Ngoc Thanh and Hwang, Dosam},
	month = may,
	year = {2023},
	pmid = {36999094},
	pmcid = {PMC10036155},
	pages = {110235},
	file = {PubMed Central Full Text PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/D3RKA7JM/Phan et al. - 2023 - Fake news detection A survey of graph neural netw.pdf:application/pdf},
}

@article{michail_detection_2022,
	title = {Detection of fake news campaigns using graph convolutional networks},
	volume = {2},
	issn = {2667-0968},
	url = {https://www.sciencedirect.com/science/article/pii/S2667096822000477},
	doi = {10.1016/j.jjimei.2022.100104},
	abstract = {The detection of organised disinformation campaigns that spread fake news, by first camouflaging them as real ones is crucial in the battle against misinformation and disinformation in social media. This article presents a method for classifying the diffusion graphs of news formed in social media, by taking into account the profiles of the users that participate in the graph, the profiles of their social relations and the way the news spread, ignoring the actual text content of the news or the messages that spread it. This increases the robustness of the method and widens its applicability in different contexts. The results of this study show that the proposed method outperforms methods that rely on textual information only and provide a model that can be employed for detecting similar disinformation campaigns on different context in the same social medium.},
	number = {2},
	urldate = {2024-05-15},
	journal = {International Journal of Information Management Data Insights},
	author = {Michail, Dimitrios and Kanakaris, Nikos and Varlamis, Iraklis},
	month = nov,
	year = {2022},
	keywords = {Astroturfing, Disinformation, Fake news, Graph attention networks, Graph convolutional networks},
	pages = {100104},
	file = {ScienceDirect Snapshot:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/7SRJH6K9/S2667096822000477.html:text/html},
}

@article{gao_echo_2023,
	title = {Echo chamber effects on short video platforms},
	volume = {13},
	issn = {2045-2322},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10111082/},
	doi = {10.1038/s41598-023-33370-1},
	abstract = {In recent years, short videos have become an increasingly vital source of information. To compete for users’ attention, short video platforms have been overusing algorithmic technology, making the group polarization intensify, which is likely to push users into the homogeneous “echo chamber”. However, echo chambers can contribute to the spread of misleading information, false news, or rumors, which have negative social impacts. Therefore, it is necessary to explore echo chamber effects in short video platforms. Moreover, the communication paradigms between users and feed algorithms greatly vary across short video platforms. This paper investigated echo chamber effects of three popular short video platforms (Douyin, TikTok, and Bilibili) using social network analysis and explored how user features influenced the generation of echo chambers. We quantified echo chamber effects through two primary ingredients: selective exposure and homophily, in both platform and topic dimensions. Our analyses indicate that the gathering of users into homogeneous groups dominates online interactions on Douyin and Bilibili. We performed performance comparison of echo chamber effects and found that echo chamber members tend to display themselves to attract the attention of their peers and that cultural differences can prevent the development of echo chambers. Our findings are of great value in designing targeted management strategies to prevent the spread of misleading information, false news, or rumors.},
	urldate = {2024-05-15},
	journal = {Scientific Reports},
	author = {Gao, Yichang and Liu, Fengming and Gao, Lei},
	month = apr,
	year = {2023},
	pmid = {37072484},
	pmcid = {PMC10111082},
	pages = {6282},
	file = {PubMed Central Full Text PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/NKNM8PAU/Gao et al. - 2023 - Echo chamber effects on short video platforms.pdf:application/pdf},
}

@article{tornberg_echo_2018,
	title = {Echo chambers and viral misinformation: {Modeling} fake news as complex contagion},
	volume = {13},
	issn = {1932-6203},
	shorttitle = {Echo chambers and viral misinformation},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0203958},
	doi = {10.1371/journal.pone.0203958},
	abstract = {The viral spread of digital misinformation has become so severe that the World Economic Forum considers it among the main threats to human society. This spread have been suggested to be related to the similarly problematized phenomenon of “echo chambers”, but the causal nature of this relationship has proven difficult to disentangle due to the connected nature of social media, whose causality is characterized by complexity, non-linearity and emergence. This paper uses a network simulation model to study a possible relationship between echo chambers and the viral spread of misinformation. It finds an “echo chamber effect”: the presence of an opinion and network polarized cluster of nodes in a network contributes to the diffusion of complex contagions, and there is a synergetic effect between opinion and network polarization on the virality of misinformation. The echo chambers effect likely comes from that they form the initial bandwagon for diffusion. These findings have implication for the study of the media logic of new social media.},
	language = {en},
	number = {9},
	urldate = {2024-05-15},
	journal = {PLOS ONE},
	author = {Törnberg, Petter},
	month = sep,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Forests, Graphs, Network analysis, Simulation and modeling, Social media, Social networks, Social theory, Twitter},
	pages = {e0203958},
	file = {Full Text PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/39NMGYLD/Törnberg - 2018 - Echo chambers and viral misinformation Modeling f.pdf:application/pdf},
}

@inproceedings{ghanem_fakeflow_2021,
	address = {Online},
	title = {{FakeFlow}: {Fake} {News} {Detection} by {Modeling} the {Flow} of {Affective} {Information}},
	shorttitle = {{FakeFlow}},
	url = {https://aclanthology.org/2021.eacl-main.56},
	doi = {10.18653/v1/2021.eacl-main.56},
	abstract = {Fake news articles often stir the readers' attention by means of emotional appeals that arouse their feelings. Unlike in short news texts, authors of longer articles can exploit such affective factors to manipulate readers by adding exaggerations or fabricating events, in order to affect the readers' emotions. To capture this, we propose in this paper to model the flow of affective information in fake news articles using a neural architecture. The proposed model, FakeFlow, learns this flow by combining topic and affective information extracted from text. We evaluate the model's performance with several experiments on four real-world datasets. The results show that FakeFlow achieves superior results when compared against state-of-the-art methods, thus confirming the importance of capturing the flow of the affective information in news articles.},
	urldate = {2024-05-15},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Ghanem, Bilal and Ponzetto, Simone Paolo and Rosso, Paolo and Rangel, Francisco},
	editor = {Merlo, Paola and Tiedemann, Jorg and Tsarfaty, Reut},
	month = apr,
	year = {2021},
	pages = {679--689},
	file = {Full Text PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/DVSH6FGG/Ghanem et al. - 2021 - FakeFlow Fake News Detection by Modeling the Flow.pdf:application/pdf},
}

@article{islam_deep_2020,
	title = {Deep learning for misinformation detection on online social networks: a survey and new perspectives},
	volume = {10},
	issn = {1869-5469},
	shorttitle = {Deep learning for misinformation detection on online social networks},
	url = {https://doi.org/10.1007/s13278-020-00696-x},
	doi = {10.1007/s13278-020-00696-x},
	abstract = {Recently, the use of social networks such as Facebook, Twitter, and Sina Weibo has become an inseparable part of our daily lives. It is considered as a convenient platform for users to share personal messages, pictures, and videos. However, while people enjoy social networks, many deceptive activities such as fake news or rumors can mislead users into believing misinformation. Besides, spreading the massive amount of misinformation in social networks has become a global risk. Therefore, misinformation detection (MID) in social networks has gained a great deal of attention and is considered an emerging area of research interest. We find that several studies related to MID have been studied to new research problems and techniques. While important, however, the automated detection of misinformation is difficult to accomplish as it requires the advanced model to understand how related or unrelated the reported information is when compared to real information. The existing studies have mainly focused on three broad categories of misinformation: false information, fake news, and rumor detection. Therefore, related to the previous issues, we present a comprehensive survey of automated misinformation detection on (i) false information, (ii) rumors, (iii) spam, (iv) fake news, and (v) disinformation. We provide a state-of-the-art review on MID where deep learning (DL) is used to automatically process data and create patterns to make decisions not only to extract global features but also to achieve better results. We further show that DL is an effective and scalable technique for the state-of-the-art MID. Finally, we suggest several open issues that currently limit real-world implementation and point to future directions along this dimension.},
	language = {en},
	number = {1},
	urldate = {2024-05-15},
	journal = {Social Network Analysis and Mining},
	author = {Islam, Md Rafiqul and Liu, Shaowu and Wang, Xianzhi and Xu, Guandong},
	month = sep,
	year = {2020},
	keywords = {Decision making, Deep learning, Misinformation detection, Neural network, Online social networks},
	pages = {82},
	file = {Full Text PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/87KYZ44G/Islam et al. - 2020 - Deep learning for misinformation detection on onli.pdf:application/pdf},
}

@article{krafft_disinformation_2020,
	title = {Disinformation by {Design}: {The} {Use} of {Evidence} {Collages} and {Platform} {Filtering} in a {Media} {Manipulation} {Campaign}},
	copyright = {© 2020 The Author(s). Published with license by Taylor \& Francis Group, LLC},
	issn = {1058-4609},
	shorttitle = {Disinformation by {Design}},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10584609.2019.1686094},
	abstract = {Disinformation campaigns such as those perpetrated by far-right groups in the United States seek to erode democratic social institutions. Looking to understand these phenomena, previous models of d...},
	language = {EN},
	urldate = {2024-05-15},
	journal = {Political Communication},
	author = {Krafft, P. M. and Donovan, Joan},
	month = mar,
	year = {2020},
	note = {Publisher: Routledge},
	file = {Krafft and Donovan - 2020 - Disinformation by Design The Use of Evidence Coll.pdf:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/5WMQI46I/Krafft and Donovan - 2020 - Disinformation by Design The Use of Evidence Coll.pdf:application/pdf;Snapshot:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/XU5HWJTY/10584609.2019.html:text/html},
}

@article{guarino_characterizing_2020,
	title = {Characterizing networks of propaganda on twitter: a case study},
	volume = {5},
	copyright = {2020 The Author(s)},
	issn = {2364-8228},
	shorttitle = {Characterizing networks of propaganda on twitter},
	url = {https://appliednetsci.springeropen.com/articles/10.1007/s41109-020-00286-y},
	doi = {10.1007/s41109-020-00286-y},
	abstract = {The daily exposure of social media users to propaganda and disinformation campaigns has reinvigorated the need to investigate the local and global patterns of diffusion of different (mis)information content on social media. Echo chambers and influencers are often deemed responsible of both the polarization of users in online social networks and the success of propaganda and disinformation campaigns. This article adopts a data-driven approach to investigate the structuration of communities and propaganda networks on Twitter in order to assess the correctness of these imputations. In particular, the work aims at characterizing networks of propaganda extracted from a Twitter dataset by combining the information gained by three different classification approaches, focused respectively on (i) using Tweets content to infer the “polarization” of users around a specific topic, (ii) identifying users having an active role in the diffusion of different propaganda and disinformation items, and (iii) analyzing social ties to identify topological clusters and users playing a “central” role in the network. The work identifies highly partisan community structures along political alignments; furthermore, centrality metrics proved to be very informative to detect the most active users in the network and to distinguish users playing different roles; finally, polarization and clustering structure of the retweet graphs provided useful insights about relevant properties of users exposure, interactions, and participation to different propaganda items.},
	language = {en},
	number = {1},
	urldate = {2024-05-15},
	journal = {Applied Network Science},
	author = {Guarino, Stefano and Trino, Noemi and Celestini, Alessandro and Chessa, Alessandro and Riotta, Gianni},
	month = dec,
	year = {2020},
	note = {Number: 1
Publisher: SpringerOpen},
	pages = {1--22},
	file = {Full Text PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/MVP99ILF/Guarino et al. - 2020 - Characterizing networks of propaganda on twitter .pdf:application/pdf},
}

@article{chen_data-driven_2022,
	title = {A data-driven model for social media fake news detection},
	volume = {52},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {0253-2778},
	url = {https://justc.ustc.edu.cn/en/article/doi/10.52396/JUSTC-2021-0215},
	doi = {10.52396/JUSTC-2021-0215},
	abstract = {{\textless}p{\textgreater}The rapid development of social media leads to the spread of a large amount of false news, which not only affects people’s daily life but also harms the credibility of social media platforms. Therefore, detecting Chinese fake news is a challenging and meaningful task. However, existing fake news datasets from Chinese social media platforms have a relatively small amount of data and data collection in this field is relatively old, thus being unable to meet the requirements of further research. In consideration of this background, we release a new Chinese Weibo Fake News dataset, which contains 26320 fake news data collected from Weibo. In addition, we propose a fake news detection model based on data augmentation that can effectively solve the problem of a lack of fake news, and we improve the generalization ability and robustness of the model. We conduct numerous experiments on our Chinese Weibo Fake News dataset and successfully deploy the model on the web page. The experimental performance proves the effectiveness of the proposed end-to-end model for detecting fake news on social media platforms.{\textless}/p{\textgreater}},
	language = {en},
	number = {3},
	urldate = {2024-05-17},
	journal = {JUSTC},
	author = {Chen, Xin and Fang, Shancheng and Mao, Zhendong and Zhang, Yongdong},
	year = {2022},
	note = {Publisher: JUSTC},
	pages = {7--9},
}

@article{ansar_combating_2021,
	title = {Combating the menace: {A} survey on characterization and detection of fake news from a data science perspective},
	volume = {1},
	issn = {2667-0968},
	shorttitle = {Combating the menace},
	url = {https://www.sciencedirect.com/science/article/pii/S2667096821000458},
	doi = {10.1016/j.jjimei.2021.100052},
	abstract = {Journalism has always remained a vital constituent of our society and journalists play a key role in making people aware of the happenings and developments in society. This spread of information enables shaping the ideologies, orientations and thoughts of individuals as well as the society. Contrary to this, the spread of misinformation or fake news leads to detrimental consequences. With the advent of social media, the menace of fake news has become grievous due to the unrestrained propagation of information and difficulty to track several accounts operated by humans or bots. This menace can be mitigated through data science approaches by combining artificial intelligence with statistics and domain-based knowledge. In this paper, a survey of works aimed at characterization, feature extraction and subsequent detection of fake news has been conducted from a data science perspective. Along with it, an analysis of the 8 renowned fake news detection repositories has been presented. Furthermore, through a case study on tweets related to COVID-19 pandemic, the factors behind the spread of misinformation during critical times, distinguishing between factual and emotional tweets and viable approaches to restrain fake news has been enunciated.},
	number = {2},
	urldate = {2024-05-17},
	journal = {International Journal of Information Management Data Insights},
	author = {Ansar, Wazib and Goswami, Saptarsi},
	month = nov,
	year = {2021},
	keywords = {COVID-19, Deep learning, Fake news, Fake news data sets, Machine learning, Transformer NLP},
	pages = {100052},
}

@misc{donabauer_exploring_2022,
	title = {Exploring {Fake} {News} {Detection} with {Heterogeneous} {Social} {Media} {Context} {Graphs}},
	url = {http://arxiv.org/abs/2212.06560},
	doi = {10.48550/arXiv.2212.06560},
	abstract = {Fake news detection has become a research area that goes way beyond a purely academic interest as it has direct implications on our society as a whole. Recent advances have primarily focused on textbased approaches. However, it has become clear that to be effective one needs to incorporate additional, contextual information such as spreading behaviour of news articles and user interaction patterns on social media. We propose to construct heterogeneous social context graphs around news articles and reformulate the problem as a graph classification task. Exploring the incorporation of different types of information (to get an idea as to what level of social context is most effective) and using different graph neural network architectures indicates that this approach is highly effective with robust results on a common benchmark dataset.},
	urldate = {2024-05-17},
	publisher = {arXiv},
	author = {Donabauer, Gregor and Kruschwitz, Udo},
	month = dec,
	year = {2022},
	note = {arXiv:2212.06560 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {arXiv Fulltext PDF:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/Z8WA7ZNX/Donabauer and Kruschwitz - 2022 - Exploring Fake News Detection with Heterogeneous S.pdf:application/pdf;arXiv.org Snapshot:/Users/matthieu/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/CUEUTZG3/2212.html:text/html},
}

@article{barnabo_fbmultilingmisinfo_2022,
	title = {{FbMultiLingMisinfo}: {Challenging} {Large}-{Scale} {Multilingual} {Benchmark} for {Misinformation} {Detection}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/0140b38d66f5ce3910a7cce691240fa8fee83184},
	doi = {10.1109/IJCNN55064.2022.9892739},
	abstract = {According to recent research, geometric deep learning allows to reach unprecedented accuracy for online misinformation detection. By fully leveraging the news social context, URL propagation paths in social networks are first represented as graphs and then classified using Graph Neural Network (GNN) models. Despite these remarkable efforts, researchers are still hampered by the scarcity of high-quality benchmark datasets, and as a result, the efficacy of state-of-the-art approaches could be overestimated. So far, in order to obtain a decent number of third-party fact-checked URLs, researchers have either sampled news from notoriously reliable and unreliable sources using distant supervision, or they have gathered pre-labeled URLs from third-party fact-checking websites. In the former case, resulting datasets can be quite large, but also noisy and biased since pieces of news are labeled as true or false according to their source label, and not individually fact-checked. In the latter case, assigned labels are more reliable, but the included news articles are usually in a single language and they may reflect unknown editorial decisions. As a result, datasets of the latter type are typically small, homogeneous, and thus unrealistically easy for automatic fake news detection models. In this work, we present FbMultiLingMisinfo, a new multilingual benchmark dataset, aimed at a more realistic evaluation of state-of-the-art misinformation detection models. URLs in our dataset come from the Facebook Privacy-Protected Full URLs Data Set, which we augmented with their propagation paths on Twitter. Our experimental results show that, when GNN-based models are tested on FbMultiLingMisinfo, recent misinformation detection results are only partially confirmed. We further show that a sharp reduction in the training size significantly reduces the model accuracy on FbMultiLingMisinfo, but not on two other widely used benchmark datasets for fake news detection.},
	journal = {2022 International Joint Conference on Neural Networks (IJCNN)},
	author = {Barnabò, Giorgio and Siciliano, F. and Castillo, C. and Leonardi, S. and Nakov, Preslav and Martino, Giovanni Da San and Silvestri, F.},
	year = {2022},
	pages = {1--8},
}

@article{wang_attacking_2023,
	title = {Attacking {Fake} {News} {Detectors} via {Manipulating} {News} {Social} {Engagement}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/946981a998d7782d55fdf356a5e4423c0c1e7a52},
	doi = {10.1145/3543507.3583868},
	abstract = {Social media is one of the main sources for news consumption, especially among the younger generation. With the increasing popularity of news consumption on various social media platforms, there has been a surge of misinformation which includes false information or unfounded claims. As various text- and social context-based fake news detectors are proposed to detect misinformation on social media, recent works start to focus on the vulnerabilities of fake news detectors. In this paper, we present the first adversarial attack framework against Graph Neural Network (GNN)-based fake news detectors to probe their robustness. Specifically, we leverage a multi-agent reinforcement learning (MARL) framework to simulate the adversarial behavior of fraudsters on social media. Research has shown that in real-world settings, fraudsters coordinate with each other to share different news in order to evade the detection of fake news detectors. Therefore, we modeled our MARL framework as a Markov Game with bot, cyborg, and crowd worker agents, which have their own distinctive cost, budget, and influence. We then use deep Q-learning to search for the optimal policy that maximizes the rewards. Extensive experimental results on two real-world fake news propagation datasets demonstrate that our proposed framework can effectively sabotage the GNN-based fake news detector performance. We hope this paper can provide insights for future research on fake news detection.},
	journal = {Proceedings of the ACM Web Conference 2023},
	author = {Wang, Haoran and Dou, Yingtong and Chen, Canyu and Sun, Lichao and Yu, Philip S. and Shu, Kai},
	year = {2023},
	pages = {null},
}

@article{jung_topological_2023,
	title = {Topological and {Sequential} {Neural} {Network} {Model} for {Detecting} {Fake} {News}},
	volume = {11},
	url = {https://www.semanticscholar.org/paper/9ddb1ddc36ffc06edb02de3baac30ac0044754ea},
	doi = {10.1109/ACCESS.2023.3343843},
	abstract = {Fake news can be easily propagated through social media and cause negative societal effects. Since fake news is disinformation with malicious intent, manual fact-checking requires great effort. In order to cope with these challenges, many automatic fake news detection models have been introduced. Recent studies have shown that social network information along with news content can be used effectively for detecting fake news. In this paper, we propose a Topological and Sequential Neural Network model (TSNN) for detecting fake news by capturing the diffusion patterns between source news and users in social networks. We employ the supernode approach instead of simple graph pooling methods to extract representative features in graph topological structure. To better learn the representations in the supernode, we design two-staged graph neural networks reflecting the heterogeneity between news and Twitter users. Our model additionally captures sequential information on news diffusion path by using a transformer. We evaluate our model with two fake news benchmark datasets annotated by fact-checking websites: PolitiFact and GossipCop. TSNN achieves 92.15\% accuracy and 92.11\% F1-score on PolitiFact, and 97.91\% accuracy and 97.88\% F1-score on GossipCop. These results demonstrate that our model significantly outperforms other baselines, establishing it as a state-of-the-art solution for fake news detection. To verify the effectiveness following model configuration, we perform ablation studies to demonstrate how each component among our two-stage graph neural networks, and sequential information modules contribute to the performance improvements.},
	journal = {IEEE Access},
	author = {Jung, Dongin and Kim, Eungyeop and Cho, Yoon-Sik},
	year = {2023},
	pages = {143925--143935},
}

@article{imaduwage_mismatch_2022,
	title = {The {Mismatch} between {Graph} {Neural} {Networks}’ {Expressivity} and {Propagation} {Graphs} in {Fake} {News} {Detection}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/7a65545dda5c29379d69911f4692eb15c6ab0f3f},
	doi = {10.1109/BCD54882.2022.9900611},
	abstract = {We investigate works under the propagation-based fake news detection domain, which recently seeks to improve performance through the use of Graph Neural Networks (GNNs). Generally, existing works argue that using GNNs can give results superior to what was obtained using classic graph-based methods. We agree with this argument given that GNNs are capable of gaining superior performance by leveraging node features. But we argue that existing works haven’t identified the fact that the expressivity of GNNs is limited and bounded by node features. Existing works do not acknowledge that, by utilizing GNNs, they implicitly assume node features are strongly correlated to node labels. There are evidence that node features that have been employed do not necessarily correlate to node label. Instead of having a profound theoretical motivation, they have empirically observed that focusing on nodes features with strong feature-label correlation can increase predictive capability. This is a sub-optimal approach to view this problem, in fact, we argue that finding node features based on correlation is not practical or effective. Our first contribution is shifting readers from a node-level view i.e correlating node features with labels, to a graph-level view. In the graph-level view, we exploit the relationship between graph isomorphism and GNNs’ expressivity which can be utilized to well understand and interpret the relation between node features and GNNs’ expressivity. We conduct a wide range of experiments on basis of both node-level view and graph-level view and found graph-level view is more interpretable and strongly matches with results. Further, we gained insights on node features that wouldn’t be obtainable by a node-level view. In order to have a fair and comprehensive analysis of node features, we built a unified dataset that includes a wide range of node features. Our results indicate, as we improve model accuracy on basis of the graph level view, models’ generalizability decreases. We provide our hypothesis for this performance trade-off on the basis of the graph-level view. Our results and insights call for a much broader discussion on whether any sort of filtering method is effective. So, we conclude our work by providing readers with possible solutions that can be helpful to find harmony between node features and GNNs’ expressivity.},
	journal = {2022 IEEE/ACIS 7th International Conference on Big Data, Cloud Computing, and Data Science (BCD)},
	author = {Imaduwage, Sarith and Kumara, Ppnv and Samaraweera, W.},
	year = {2022},
	pages = {109--116},
}

@article{barnabo_deep_2023,
	title = {Deep active learning for misinformation detection using geometric deep learning},
	volume = {33},
	url = {https://www.semanticscholar.org/paper/2349a5ae444fd0d5d676a7ff7ce89a8a9eab8a2b},
	doi = {10.1016/j.osnem.2023.100244},
	abstract = {null},
	journal = {Online Soc. Networks Media},
	author = {Barnabò, Giorgio and Siciliano, F. and Castillo, C. and Leonardi, S. and Nakov, Preslav and Martino, Giovanni Da San and Silvestri, Fabrizio},
	year = {2023},
	pages = {100244},
}

@article{mehta_interactively_2023,
	title = {Interactively {Learning} {Social} {Media} {Representations} {Improves} {News} {Source} {Factuality} {Detection}},
	volume = {abs/2309.14966},
	url = {https://www.semanticscholar.org/paper/cc5b098814f5ab34c5df5dbceecab55841efc63a},
	doi = {10.48550/arXiv.2309.14966},
	abstract = {The rise of social media has enabled the widespread propagation of fake news, text that is published with an intent to spread misinformation and sway beliefs. Rapidly detecting fake news, especially as new events arise, is important to prevent misinformation. While prior works have tackled this problem using supervised learning systems, automatedly modeling the complexities of the social media landscape that enables the spread of fake news is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where humans can interact to help an automated system learn a better social media representation quality. On real world events, our experiments show performance improvements in detecting factuality of news sources, even after few human interactions.},
	journal = {ArXiv},
	author = {Mehta, Nikhil and Goldwasser, Dan},
	year = {2023},
	pages = {null},
}

@article{mwangi_technology_2023,
	title = {Technology and {Fake} {News}: {Shaping} {Social}, {Political}, and {Economic} {Perspectives}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/36fbcb827976e80e5dd6fe31462a02f51d5e1a7c},
	doi = {10.2139/ssrn.4462727},
	abstract = {This article explores the impact of technology on the proliferation of fake news and its consequent effects on social, political, and economic perspectives. With the rise of digital platforms and the democratization of information, fake news has become a pervasive issue in contemporary society. This article examines the underlying factors contributing to the spread of fake news, including the role of social media algorithms, echo chambers, and information manipulation. Moreover, it discusses the far- reaching consequences of fake news, such as erosion of trust, political polarization, and economic implications. By analyzing various case studies and scholarly research, this article aims to shed light on the multifaceted relationship between technology, fake news, and its broader societal impact.},
	journal = {SSRN Electronic Journal},
	author = {Mwangi, E.},
	year = {2023},
	pages = {null},
}

@article{chen_leveraging_2022,
	title = {Leveraging {Diversity}-{Aware} {Context} {Attention} {Networks} for {Fake} {News} {Detection} on {Social} {Platforms}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/8328de9fcabcd24ecb1ffa44269bc7b079cae518},
	doi = {10.1109/IJCNN55064.2022.9892488},
	abstract = {In recent years, social platforms have become the main venue for disseminating fake news. Since much fake news is deliberately fabricated by malicious users or generated by adversarial deep learning models, content-only approaches can not detect fake news effectively. Compared to texts, the propagation patterns of fake news are much harder to be forged. Recent work found that the “context” of news, the tree-structured graph representing the propagation relationship of news and Twitter posts, is vital for fake news detection. Some work utilize graph neural networks to learn the representation of news' context graphs, achieving stunning performance. However, these methods still suffer from two problems. Firstly, Twitters posts in the context of news are not equally important for fake news detection. However, most previous works treat them equally. Moreover, the context of news presents diverse structures such as “star-shaped” graphs, with many nodes interacting with a central node, or “line-shaped” graphs, with sparse connections among neighbors. With single-scale graph representation, previous work can not handle diverse structures well. We propose a novel diversity-aware context attention network to cope with these problems. A context attention pooling function is proposed to extract the critical information within the context. It utilizes an attention module to automatically assign a greater weight to those important posts and a smaller weight to helpless posts. Furthermore, jump knowledge, which concatenates the pooling result from multiple network layers, is adopted. It offers the model multi-scale receptive fields and better adapts to diverse structures. Extensive experiments are conducted under various dataset settings, which confirms the superiority of our approaches over state-of-the-art models.},
	journal = {2022 International Joint Conference on Neural Networks (IJCNN)},
	author = {Chen, Zhikai and Wu, Peng and Pan, Liang X.},
	year = {2022},
	pages = {01--08},
}

@article{jeong_nothing_2022,
	title = {Nothing {Stands} {Alone}: {Relational} {Fake} {News} {Detection} with {Hypergraph} {Neural} {Networks}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/cf0b4eba5424fd0302c2f7c9ac3b4a4120a29dbe},
	doi = {10.1109/BigData55660.2022.10020234},
	abstract = {Nowadays, fake news easily propagates through online social networks and becomes a grand threat to individuals and society. Assessing the authenticity of news is challenging due to its elaborately fabricated contents, making it difficult to obtain large-scale annotations for fake news data. Due to such data scarcity issues, detecting fake news tends to fail and overfit in the supervised setting. Recently, graph neural networks (GNNs) have been adopted to leverage the richer relational information among both labeled and unlabeled instances. Despite their promising results, they are inherently focused on pairwise relations between news, which can limit the expressive power for capturing fake news that spreads in a group-level. For example, detecting fake news can be more effective when we better understand relations between news pieces shared among susceptible users. To address those issues, we propose to leverage a hypergraph to represent group-wise interaction among news, while focusing on important news relations with its dual-level attention mechanism. Experiments based on two benchmark datasets show that our approach yields remarkable performance and maintains the high performance even with a small subset of labeled news data.},
	journal = {2022 IEEE International Conference on Big Data (Big Data)},
	author = {Jeong, Ujun and Ding, Kaize and Cheng, Lu and Guo, Ruocheng and Shu, Kai and Liu, Huan},
	year = {2022},
	pages = {596--605},
}

@article{chen_multi-view_2022,
	title = {Multi-view learning with distinguishable feature fusion for rumor detection},
	volume = {240},
	url = {https://www.semanticscholar.org/paper/01ad6745edb638fd9a6319c99cead8fe04ee77d7},
	doi = {10.1016/j.knosys.2021.108085},
	abstract = {null},
	journal = {Knowl. Based Syst.},
	author = {Chen, Xueqin and Zhou, Fan and Trajcevski, Goce and Bonsangue, Marcello},
	year = {2022},
	pages = {108085},
}

@article{song_dynamic_2022,
	title = {Dynamic graph neural network for fake news detection},
	volume = {505},
	url = {https://www.semanticscholar.org/paper/fa56ada9b1f0619f7bc37b79debc625735f6aef1},
	doi = {10.1016/j.neucom.2022.07.057},
	abstract = {null},
	journal = {Neurocomputing},
	author = {Song, Chenguang and Teng, Yiyang and Zhu, Yangfu and Wei, Siqi and Wu, Bin},
	year = {2022},
	pages = {362--374},
}

@article{ansar_combating_2021-1,
	title = {Combating the menace: {A} survey on characterization and detection of fake news from a data science perspective},
	volume = {1},
	url = {https://www.semanticscholar.org/paper/b1fa4a0048901a05057944b6de10d00c2d8c6ea1},
	doi = {10.1016/j.jjimei.2021.100052},
	abstract = {S2 TL;DR: A survey of works aimed at characterization, feature extraction and subsequent detection of fake news has been conducted from a data science perspective, and an analysis of the 8 renowned fake news detection repositories has been presented.},
	journal = {Int. J. Inf. Manag. Data Insights},
	author = {Ansar, Wazib and Goswami, Saptarsi},
	year = {2021},
	pages = {100052},
}

@article{vasist_tackling_2022,
	title = {Tackling the infodemic during a pandemic: {A} comparative study on algorithms to deal with thematically heterogeneous fake news},
	volume = {2},
	url = {https://www.semanticscholar.org/paper/c67d16d2191716dd5ee0dd9e8a26ddaa02d1042a},
	doi = {10.1016/j.jjimei.2022.100133},
	abstract = {null},
	journal = {Int. J. Inf. Manag. Data Insights},
	author = {Vasist, Pramukh Nanjundaswamy and Sebastian, M.},
	year = {2022},
	pages = {100133},
}

@article{varlamis_survey_2022,
	title = {A {Survey} on the {Use} of {Graph} {Convolutional} {Networks} for {Combating} {Fake} {News}},
	volume = {14},
	url = {https://www.semanticscholar.org/paper/266b1e04bb037cbe5d8d62ef695b8ee61e1dd4ee},
	doi = {10.3390/fi14030070},
	abstract = {The combat against fake news and disinformation is an ongoing, multi-faceted task for researchers in social media and social networks domains, which comprises not only the detection of false facts in published content but also the detection of accountability mechanisms that keep a record of the trustfulness of sources that generate news and, lately, of the networks that deliberately distribute fake information. In the direction of detecting and handling organized disinformation networks, major social media and social networking sites are currently developing strategies and mechanisms to block such attempts. The role of machine learning techniques, especially neural networks, is crucial in this task. The current work focuses on the popular and promising graph representation techniques and performs a survey of the works that employ Graph Convolutional Networks (GCNs) to the task of detecting fake news, fake accounts and rumors that spread in social networks. It also highlights the available benchmark datasets employed in current research for validating the performance of the proposed methods. This work is a comprehensive survey of the use of GCNs in the combat against fake news and aims to be an ideal starting point for future researchers in the field.},
	journal = {Future Internet},
	author = {Varlamis, Iraklis and Michail, D. and Glykou, Foteini and Tsantilas, Panagiotis},
	year = {2022},
	pages = {70},
}

@article{zheng_find_2023,
	title = {Find {Indicative} {Users} for {Rumor} {Detection} {Using} {User} {Credibility} and {Stance}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/5737fa726a94d5bbc12fcb6c4522bddea2708cda},
	doi = {10.1109/ICC45041.2023.10279801},
	abstract = {Recently rumors have been rapidly propagated while the Internet has been extensively developed. Research shows that highly credible comments with a distinct stance have worthy information. In this paper, we attempt to combine user credibility and user stance to capture worthy comments during the information-dissemination process to detect rumors. We propose a User Stance Bi-Directional Graph Attention Networks (USBGAT) model to extract accurate information for rumor detection based on high credibility users with strong stance, and diminish ineffectively neutral comments. Specifically, we take user features and user stance as a component of the node features, with multiviews features of tweets content engaged. Then, we use bidirectional graph attention networks (GAT) to capture the high-level representation of the rumor. Furthermore, we reweight the node features according to users' stances. Extensive experiments on two datasets: Pheme and Weibo show that our model is superior to the state-of-the-art models, especially in the early rumor detection. Our code and data are available at https://github.com/TAN-OpenLab/USB-GAT},
	journal = {ICC 2023 - IEEE International Conference on Communications},
	author = {Zheng, Yuansong and Tan, Zhenhua and Wu, Danke and Ning, Jingyu},
	year = {2023},
	pages = {2846--2851},
}

@article{saikia_modelling_2022,
	title = {Modelling {Social} {Context} for {Fake} {News} {Detection}: {A} {Graph} {Neural} {Network} {Based} {Approach}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/1992b3467c20b20eb1d9dd7174a79d1da820ce09},
	doi = {10.1109/IJCNN55064.2022.9892311},
	abstract = {Detection of fake news is crucial to ensure the authenticity of information and maintain the news ecosystem's reliability. Recently, there has been an increase in fake news content due to the recent proliferation of social media and fake content generation techniques such as Deep-Fake. The majority of the existing modalities of fake news detection focus on content-based approaches. However, most of these techniques fail to deal with ultra-realistic synthesized media produced by generative models. Our recent studies find that the propagation characteristics of authentic and fake news are distinguishable, irrespective of their modalities. In this regard, we have investigated the auxiliary information based on social context to detect fake news. This paper has analyzed the social context of fake news detection with a hybrid graph neural network-based approach. This hybrid model is based on integrating a graph neural network on the propagation of news and bi-directional encoder representations from the transformers model on news content to learn the text features. Thus this proposed approach learns the content as well as the context features and hence able to outperform the baseline models with an f1-score of 0.91 on Politifact and 0.93 on the Gossipcop dataset, respectively},
	journal = {2022 International Joint Conference on Neural Networks (IJCNN)},
	author = {Saikia, P. and Gundale, Kshitij and Jain, A. and Jadeja, Dev and Patel, Harvi and Roy, Mohendra},
	year = {2022},
	pages = {01--08},
}

@article{dou_user_2021,
	title = {User {Preference}-aware {Fake} {News} {Detection}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/081a386a2a314b5bc2da6fd20ed3e7cafbcad76e},
	doi = {10.1145/3404835.3462990},
	abstract = {Disinformation and fake news have posed detrimental effects on individuals and society in recent years, attracting broad attention to fake news detection. The majority of existing fake news detection algorithms focus on mining news content and/or the surrounding exogenous context for discovering deceptive signals; while the endogenous preference of a user when he/she decides to spread a piece of fake news or not is ignored. The confirmation bias theory has indicated that a user is more likely to spread a piece of fake news when it confirms his/her existing beliefs/preferences. Users' historical, social engagements such as posts provide rich information about users' preferences toward news and have great potentials to advance fake news detection. However, the work on exploring user preference for fake news detection is somewhat limited. Therefore, in this paper, we study the novel problem of exploiting user preference for fake news detection. We propose a new framework, UPFD, which simultaneously captures various signals from user preferences by joint content and graph modeling. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework. We release our code and data as a benchmark for GNN-based fake news detection: https://github.com/safe-graph/GNN-FakeNews.},
	journal = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Dou, Yingtong and Shu, Kai and Xia, Congyin and Yu, Philip S. and Sun, Lichao},
	year = {2021},
	pages = {null},
}

@article{han_knowledge_2021,
	title = {Knowledge {Enhanced} {Multi}-modal {Fake} {News} {Detection}},
	volume = {abs/2108.04418},
	url = {https://www.semanticscholar.org/paper/04db62a14f78f693d6bd14a4803b9b73325b36bb},
	abstract = {Recent years have witnessed the significant damage caused by various types of fake news. Although considerable effort has been applied to address this issue and much progress has been made on detecting fake news, most existing approaches mainly rely on the textual content and/or social context, while knowledge-level information—entities extracted from the news content and the relations between them—is much less explored. Within the limited work on knowledge-based fake news detection, an external knowledge graph is often required, which may introduce additional problems: it is quite common for entities and relations, especially with respect to new concepts, to be missing in existing knowledge graphs, and both entity prediction and link prediction are open research questions themselves. Therefore, in this work, we investigate \textbf{knowledge-based fake news detection that does not require any external knowledge graph.} Specifically, our contributions include: (1) transforming the problem of detecting fake news into a subgraph classification task—entities and relations are extracted from each news item to form a single knowledge graph, where a news item is represented by a subgraph. Then a graph neural network (GNN) model is trained to classify each subgraph/news item. (2) Further improving the performance of this model through a simple but effective multi-modal technique that combines extracted knowledge, textual content and social context. Experiments on multiple datasets with thousands of labelled news items demonstrate that our knowledge-based algorithm outperforms existing counterpart methods, and its performance can be further boosted by the multi-modal approach.},
	journal = {ArXiv},
	author = {Han, Yi and Silva, Amila and Luo, Ling and Karunasekera, S. and Leckie, C.},
	year = {2021},
	pages = {null},
}

@article{silva_propagation2vec_2021,
	title = {{Propagation2Vec}: {Embedding} partial propagation networks for explainable fake news early detection},
	volume = {58},
	url = {https://www.semanticscholar.org/paper/c4940b22256d556051d3358b287b0aeb0369d6b9},
	doi = {10.1016/J.IPM.2021.102618},
	abstract = {S2 TL;DR: Propagation2Vec is proposed, a novel fake news early detection technique, which assigns varying levels of importance for the nodes and cascades in propagation networks, and reconstructs the knowledge of complete propagation networks based on their partial propagation networks at an early detection deadline.},
	journal = {Inf. Process. Manag.},
	author = {Silva, Amila and Han, Yi and Luo, Ling and Karunasekera, S. and Leckie, C.},
	year = {2021},
	pages = {102618},
}

@article{jin_towards_2021,
	title = {Towards {Fine}-{Grained} {Reasoning} for {Fake} {News} {Detection}},
	volume = {abs/2110.15064},
	url = {https://www.semanticscholar.org/paper/21d54922f3f9441d9fb1d05925d33ebbc60e0b12},
	doi = {10.1609/aaai.v36i5.20517},
	abstract = {The detection of fake news often requires sophisticated reasoning skills, such as logically combining information by considering word-level subtle clues. In this paper, we move towards fine-grained reasoning for fake news detection by better reflecting the logical processes of human thinking and enabling the modeling of subtle clues. In particular, we propose a fine-grained reasoning framework by following the human’s information-processing model, introduce a mutual-reinforcement-based method for incorporating human knowledge about which evidence is more important, and design a prior-aware bi-channel kernel graph network to model subtle differences between pieces of evidence. Extensive experiments show that our model outperforms the state-of-the-art methods and demonstrate the explainability of our approach.},
	journal = {ArXiv},
	author = {Jin, Yiqiao and Wang, Xiting and Yang, Ruichao and Sun, Yizhou and Wang, Wei and Liao, Hao and Xie, Xing},
	year = {2021},
	pages = {null},
}

@article{yang_entity-aware_2023,
	title = {Entity-{Aware} {Dual} {Co}-{Attention} {Network} for {Fake} {News} {Detection}},
	url = {https://www.semanticscholar.org/paper/ad0cb6aefc29e0a36ec3a6027cd642ffa2586ad7},
	doi = {10.48550/arXiv.2302.03475},
	abstract = {Fake news and misinformation spread rapidly on the Internet. How to identify it and how to interpret the identification results have become important issues. In this paper, we propose a Dual Co-Attention Network (Dual-CAN) for fake news detection, which takes news content, social media replies, and external knowledge into consideration. Our experimental results support that the proposed Dual-CAN outperforms current representative models in two benchmark datasets. We further make in-depth discussions by comparing how models work in both datasets with empirical analysis of attention weights.},
	author = {Yang, Sin-Han and Chen, Chung-Chi and Huang, Hen-Hsen and Chen, Hsin-Hsi},
	year = {2023},
}

@article{wu_probing_2022,
	title = {Probing {Spurious} {Correlations} in {Popular} {Event}-{Based} {Rumor} {Detection} {Benchmarks}},
	url = {https://www.semanticscholar.org/paper/f47f80699094859dfa7ecc57172a3ed433ee26d7},
	doi = {10.48550/arXiv.2209.08799},
	abstract = {As social media becomes a hotbed for the spread of misinformation, the crucial task of rumor detection has witnessed promising advances fostered by open-source benchmark datasets. Despite being widely used, we find that these datasets suffer from spurious correlations, which are ignored by existing studies and lead to severe overestimation of existing rumor detection performance. The spurious correlations stem from three causes: (1) event-based data collection and labeling schemes assign the same veracity label to multiple highly similar posts from the same underlying event; (2) merging multiple data sources spuriously relates source identities to veracity labels; and (3) labeling bias. In this paper, we closely investigate three of the most popular rumor detection benchmark datasets (i.e., Twitter15, Twitter16 and PHEME), and propose event-separated rumor detection as a solution to eliminate spurious cues. Under the event-separated setting, we observe that the accuracy of existing state-of-the-art models drops significantly by over 40\%, becoming only comparable to a simple neural classifier. To better address this task, we propose Publisher Style Aggregation (PSA), a generalizable approach that aggregates publisher posting records to learn writing style and veracity stance. Extensive experiments demonstrate that our method outperforms existing baselines in terms of effectiveness, efficiency and generalizability.},
	author = {Wu, Jiaying and Hooi, Bryan},
	year = {2022},
}

@article{azarijoo_meta_2023,
	title = {A {Meta} {Path}-based {Approach} for {Rumor} {Detection} on {Social} {Media}},
	volume = {abs/2301.04341},
	url = {https://www.semanticscholar.org/paper/cd8c03eea679387ed447446967b9f141f2bd5eff},
	doi = {10.48550/arXiv.2301.04341},
	abstract = {The prominent role of social media in people's daily lives has made them more inclined to receive news through social networks than traditional sources. This shift in public behavior has opened doors for some to diffuse fake news on social media; and subsequently cause negative economic, political, and social consequences as well as distrust among the public. There are many proposed methods to solve the rumor detection problem, most of which do not take full advantage of the heterogeneous nature of news propagation networks. With this intention, we considered a previously proposed architecture as our baseline and performed the idea of structural feature extraction from the heterogeneous rumor propagation over its architecture using the concept of meta path-based embeddings. We named our model Meta Path-based Global Local Attention Network (MGLAN). Extensive experimental analysis on three state-of-the-art datasets has demonstrated that MGLAN outperforms other models by capturing node-level discrimination to different node types.},
	journal = {ArXiv},
	author = {Azarijoo, Bita and Salehi, Mostafa and Najari, S.},
	year = {2023},
	pages = {null},
}

@article{mehta_tackling_2022,
	title = {Tackling {Fake} {News} {Detection} by {Continually} {Improving} {Social} {Context} {Representations} using {Graph} {Neural} {Networks}},
	url = {https://www.semanticscholar.org/paper/5d16fe889a6f0738c59c3023744f728d1f59c0d4},
	doi = {10.18653/v1/2022.acl-long.97},
	abstract = {Easy access, variety of content, and fast widespread interactions are some of the reasons making social media increasingly popular. However, this rise has also enabled the propagation of fake news, text published by news sources with an intent to spread misinformation and sway beliefs. Detecting it is an important and challenging problem to prevent large scale misinformation and maintain a healthy society. We view fake news detection as reasoning over the relations between sources, articles they publish, and engaging users on social media in a graph framework. After embedding this information, we formulate inference operators which augment the graph edges by revealing unobserved interactions between its elements, such as similarity between documents’ contents and users’ engagement patterns. Our experiments over two challenging fake news detection tasks show that using inference operators leads to a better understanding of the social media framework enabling fake news spread, resulting in improved performance.},
	author = {Mehta, Nikhil and Pacheco, Maria Leonor and Goldwasser, Dan},
	year = {2022},
}

@article{benamira_tahid_2022,
	title = {{TaHiD}: {Tackling} {Data} {Hiding} in {Fake} {News} {Detection} with {News} {Propagation} {Networks}},
	url = {https://www.semanticscholar.org/paper/914e465fd6301eae01bb8eb604726bfc4cab249c},
	abstract = {Fake news with detrimental societal effects has 001 attracted extensive attention and research. De-002 spite early success, the state-of-the-art meth-003 ods fall short of considering the propagation 004 of news. News propagates at different times 005 through different mediums, including users, 006 comments, and sources, which form the news 007 propagation network. Moreover, the serious 008 problem of data hiding arises, which means 009 that fake news publishers disguise fake news 010 as real to confuse users by deleting comments 011 that refute the rumor or deleting the news itself 012 when it has been spread widely. Existing meth-013 ods do not consider the propagation of news 014 and fail to identify what matters in the process, 015 which leads to fake news hiding in the prop-016 agation network and escaping from detection. 017 Inspired by the propagation of news, we pro-018 pose a novel fake news detection framework 019 named TaHiD, which models the propagation 020 as a heterogeneous dynamic graph and contains 021 the propagation attention module to measure 022 the influence of different propagation. Exper-023 iments demonstrate that TaHiD extracts use-024 ful information from the news propagation net-025 work and outperforms state-of-the-art methods 026 on several benchmark datasets for fake news 027 detection. Additional studies also show that 028 TaHiD is capable of identifying fake news in 029 the case of data hiding. 030},
	author = {Benamira, Adrien and Devillers, Benjamin and Lesot, Etienne and Ray, Ayush K. and Saadi, Manal and D 587, Fragkiskos and Bird, Steven and Klein, Ewan and Loper, E. and {Nat-593} and Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara and Dementieva, Daryna and Panchenko, Alexander and Devlin, J. and Chang, Ming-Wei and Lee, Kenton and Vaswani, Ashish and Shazeer, Noam M. and Parmar, Niki and Romero, Adriana and Lio, Pietro and Bengio, Y. and Wang, Yaqing and Ma, Fenglong and Jin, Zhiwei and Yuan, Ye},
	year = {2022},
}

@article{wei_unified_2022,
	title = {A {Unified} {Propagation} {Forest}-based {Framework} for {Fake} {News} {Detection}},
	url = {https://www.semanticscholar.org/paper/62907ad14a5d75d8f3d22f6ace59207fc9b4767f},
	abstract = {Fake news’s quick propagation on social media brings severe social ramifications and economic damage. Previous fake news detection usually learn semantic and structural patterns within a single target propagation tree. However, they are usually limited in narrow signals since they do not consider latent information cross other propagation trees. Motivated by a common phenomenon that most fake news is published around a specific hot event/topic, this paper develops a new concept of propagation forest to naturally combine propagation trees in a semantic-aware clustering. We propose a novel Unified Propagation Forest-based framework (UniPF) to fully explore latent correlations between propagation trees to improve fake news detection. Besides, we design a root-induced training strategy, which encourages representations of propagation trees to be closer to their prototypical root nodes. Extensive experiments on four benchmarks consistently suggest the effectiveness and scalability of UniPF.},
	author = {Wei, Lingwei and Hu, Dou and Lai, Yantong and Zhou, Wei and Hu, Songlin},
	year = {2022},
}

@article{wang_real-time_2022,
	title = {A real-time monitoring method of public opinion evolution based on dynamic social network},
	url = {https://www.semanticscholar.org/paper/6e02f654e480a56cd024502279053a3561bbcde0},
	doi = {10.1117/12.2635786},
	abstract = {Due to the popularity of social media, rumors spread rapidly on social network, which has been damaging the public trust system and social stability. In recent years, the research on rumor monitoring and early warning has attracted much researchers’ attention. In order to make full use of social network interaction information, researchers use this information to enhance tweets text to improve the performance of rumor monitor. However, most of these methods have to obtain static and complete network structures before their algorithms work, while nodes and edges are constantly evolving in practice. These methods are not only ineffective in evolutionary network structures, but also time and memory consuming, which will directly affect the feasibility of dynamic monitoring of Internet public opinion. In view of the above challenge, this paper proposes a dynamic graph learning method based on interactive information of social networks, which integrates network structure, context semantic and sequential information, especially simplifies the computational complexity of social network evolution. We have carried out a large number of experiments on a largescale real dataset. The experimental results show that our proposed model is better than the existing rumor detection methods.},
	author = {Wang, Yongyue and Liu, Zhuodong and Jiang, Changnan and Chen, Chen and Xia, C.},
	year = {2022},
}

@article{choi_dynamic_2021,
	title = {Dynamic graph convolutional networks with attention mechanism for rumor detection on social media},
	volume = {16},
	url = {https://www.semanticscholar.org/paper/f929adf3033e64c7a2bcff054d48c4abf3538d55},
	doi = {10.1371/journal.pone.0256039},
	abstract = {Social media has become an ideal platform for the propagation of rumors, fake news, and misinformation. Rumors on social media not only mislead online users but also affect the real world immensely. Thus, detecting the rumors and preventing their spread became an essential task. Some of the recent deep learning-based rumor detection methods, such as Bi-Directional Graph Convolutional Networks (Bi-GCN), represent rumor using the completed stage of the rumor diffusion and try to learn the structural information from it. However, these methods are limited to represent rumor propagation as a static graph, which isn’t optimal for capturing the dynamic information of the rumors. In this study, we propose novel graph convolutional networks with attention mechanisms, named Dynamic GCN, for rumor detection. We first represent rumor posts with their responsive posts as dynamic graphs. The temporal information is used to generate a sequence of graph snapshots. The representation learning on graph snapshots with attention mechanism captures both structural and temporal information of rumor spreads. The conducted experiments on three real-world datasets demonstrate the superiority of Dynamic GCN over the state-of-the-art methods in the rumor detection task.},
	journal = {PLoS ONE},
	author = {Choi, Jiho and Ko, Taewook and Choi, Younhyuk and Byun, HyungHo and Kim, Chong-kwon},
	year = {2021},
	pmid = {34407111},
	pages = {null},
}

@article{wu_decor_2023,
	title = {{DECOR}: {Degree}-{Corrected} {Social} {Graph} {Refinement} for {Fake} {News} {Detection}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/769ff23ad4417e5284798cc5f1297ae5c9157fd9},
	doi = {10.1145/3580305.3599298},
	abstract = {Recent efforts in fake news detection have witnessed a surge of interest in using graph neural networks (GNNs) to exploit rich social context. Existing studies generally leverage fixed graph structures, assuming that the graphs accurately represent the related social engagements. However, edge noise remains a critical challenge in real-world graphs, as training on suboptimal structures can severely limit the expressiveness of GNNs. Despite initial efforts in graph structure learning (GSL), prior works often leverage node features to update edge weights, resulting in heavy computational costs that hinder the methods' applicability to large-scale social graphs. In this work, we approach the fake news detection problem with a novel aspect of social graph refinement. We find that the degrees of news article nodes exhibit distinctive patterns, which are indicative of news veracity. Guided by this, we propose DECOR, a novel application of Degree-Corrected Stochastic Blockmodels to the fake news detection problem. Specifically, we encapsulate our empirical observations into a lightweight social graph refinement component that iteratively updates the edge weights via a learnable degree correction mask, which allows for joint optimization with a GNN-based detector. Extensive experiments on two real-world benchmarks validate the effectiveness and efficiency of DECOR1.},
	journal = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	author = {Wu, Jiaying and Hooi, Bryan},
	year = {2023},
	pages = {null},
}

@article{tseng_kahan_2022,
	title = {{KAHAN}: {Knowledge}-{Aware} {Hierarchical} {Attention} {Network} for {Fake} {News} detection on {Social} {Media}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/49f5bc8609bd15b47904356eb4319214ea6c36b5},
	doi = {10.1145/3487553.3524664},
	abstract = {In recent years, fake news detection has attracted a great deal of attention due to the myriad amounts of misinformation. Some previous methods have focused on modeling the news content, while others have combined user comments and user information on social media. However, existing methods ignore some important clues for detecting fake news, such as temporal information on social media and external knowledge related to the news. To this end, we propose a Knowledge-Aware Hierarchical Attention Network (KAHAN) that integrates this information into the model to establish fact-based associations with entities in the news content. Specifically, we introduce two hierarchical attention networks to model news content and user comments respectively, in which news content and user comments are represented by different aspects for modeling various degrees of semantic granularity. Besides, to process the random occurrences of user comments at post-level, we further designed a time-based subevent division algorithm to aggregate user comments at subevent-level to learn temporal patterns. Moreover, News towards Entities (N-E) attention and Comments towards Entities (C-E) attention are introduced to measure the importance of external knowledge. Finally, we detected the veracity of the news by combining the three aspects of news: content, user comments, and external knowledge. We conducted extensive experiments and ablation studies on two real-world datasets and showed that our proposed method outperformed the previous methods and empirically validated each component of KAHAN1.},
	journal = {Companion Proceedings of the Web Conference 2022},
	author = {Tseng, Yu-Wun and Yang, Hui-Kuo and Wang, Wei-Yao and Peng, Wen-Chih},
	year = {2022},
	pages = {null},
}

@article{yang_reinforcement_2022,
	title = {Reinforcement {Subgraph} {Reasoning} for {Fake} {News} {Detection}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/4fcdef18e15b14b193d64a0a8be83a784b58f791},
	doi = {10.1145/3534678.3539277},
	abstract = {The wide spread of fake news has caused serious societal issues. We propose a subgraph reasoning paradigm for fake news detection, which provides a crystal type of explainability by revealing which subgraphs of the news propagation network are the most important for news verification, and concurrently improves the generalization and discrimination power of graph-based detection models by removing task-irrelevant information. In particular, we propose a reinforced subgraph generation method, and perform fine-grained modeling on the generated subgraphs by developing a Hierarchical Path-aware Kernel Graph Attention Network. We also design a curriculum-based optimization method to ensure better convergence and train the two parts in an end-to-end manner.},
	journal = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	author = {Yang, Ruichao and Wang, Xiting and Jin, Yiqiao and Li, Chaozhuo and Lian, Jianxun and Xie, Xing},
	year = {2022},
	pages = {null},
}

@article{han_graph_2020,
	title = {Graph {Neural} {Networks} with {Continual} {Learning} for {Fake} {News} {Detection} from {Social} {Media}},
	volume = {abs/2007.03316},
	url = {https://www.semanticscholar.org/paper/f90c9f34a1214d07e4e36b5e9f430fc8a733f4d1},
	abstract = {Although significant effort has been applied to fact-checking, the prevalence of fake news over social media, which has profound impact on justice, public trust and our society, remains a serious problem. In this work, we focus on propagation-based fake news detection, as recent studies have demonstrated that fake news and real news spread differently online. Specifically, considering the capability of graph neural networks (GNNs) in dealing with non-Euclidean data, we use GNNs to differentiate between the propagation patterns of fake and real news on social media. In particular, we concentrate on two questions: (1) Without relying on any text information, e.g., tweet content, replies and user descriptions, how accurately can GNNs identify fake news? Machine learning models are known to be vulnerable to adversarial attacks, and avoiding the dependence on text-based features can make the model less susceptible to the manipulation of advanced fake news fabricators. (2) How to deal with new, unseen data? In other words, how does a GNN trained on a given dataset perform on a new and potentially vastly different dataset? If it achieves unsatisfactory performance, how do we solve the problem without re-training the model on the entire data from scratch? We study the above questions on two datasets with thousands of labelled news items, and our results show that: (1) GNNs can achieve comparable or superior performance without any text information to state-of-the-art methods. (2) GNNs trained on a given dataset may perform poorly on new, unseen data, and direct incremental training cannot solve the problem—this issue has not been addressed in the previous work that applies GNNs for fake news detection. In order to solve the problem, we propose a method that achieves balanced performance on both existing and new datasets, by using techniques from continual learning to train GNNs incrementally.},
	journal = {ArXiv},
	author = {Han, Yi and Karunasekera, S. and Leckie, C.},
	year = {2020},
	pages = {null},
}

@article{su_mining_2022,
	title = {Mining {User}-aware {Multi}-relations for {Fake} {News} {Detection} in {Large} {Scale} {Online} {Social} {Networks}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/64be7eeb65be5d24ed75129fb051824cf914ecb2},
	doi = {10.1145/3539597.3570478},
	abstract = {Users' involvement in creating and propagating news is a vital aspect of fake news detection in online social networks. Intuitively, credible users are more likely to share trustworthy news, while untrusted users have a higher probability of spreading untrustworthy news. In this paper, we construct a dual-layer graph (i.e., news layer and user layer) to extract multi-relations of news and users in social networks to derive rich information for detecting fake news. Based on the dual-layer graph, we propose a fake news detection model Us-DeFake. It learns the propagation features of news in the news layer and the interaction features of users in the user layer. Through the inter-layer in the graph, Us-DeFake fuses the user signals that contain credibility information into the news features, to provide distinctive user-aware embeddings of news for fake news detection. The training process conducts on multiple dual-layer subgraphs obtained by a graph sampler to scale Us-DeFake in large scale social networks. Extensive experiments on real-world datasets illustrate the superiority of Us-DeFake which outperforms all baselines, and the users' credibility signals learned by interaction relation can notably improve the performance of our model.},
	journal = {Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
	author = {Su, Xing and Yang, Jian and Wu, Jia and Zhang, Yuchen},
	year = {2022},
	pages = {null},
}

@article{hu_mmnet_2022,
	title = {{MMNet}: {Multi}-modal {Fusion} with {Mutual} {Learning} {Network} for {Fake} {News} {Detection}},
	volume = {abs/2212.05699},
	url = {https://www.semanticscholar.org/paper/e61cce5133aaeb50b409a7f86219261440274c99},
	doi = {10.48550/arXiv.2212.05699},
	abstract = {The rapid development of social media provides a hotbed for the dissemination of fake news, which misleads readers and causes negative effects on society. News usually involves texts and images to be more vivid. Consequently, multi-modal fake news detection has received wide attention. Prior efforts primarily conduct multi-modal fusion by simple concatenation or co-attention mechanism, leading to sub-optimal performance. In this paper, we propose a novel mutual learning network based model MMNet, which enhances the multi-modal fusion for fake news detection via mutual learning between text-and vision-centered views towards the same classification objective. Specifically, we design two detection modules respectively based on text-and vision-centered multi-modal fusion features, and enable the mutual learning of the two modules to facilitate the multi-modal fusion, considering the latent consistency between the two modules towards the same training objective. Moreover, we also consider the influence of the image-text matching degree on news authenticity judgement by designing an image-text matching aware co-attention mechanism for multi-modal fusion. Extensive experiments are conducted on three benchmark datasets and the results demonstrate that our proposed MMNet achieves superior performance in fake news detection.},
	journal = {ArXiv},
	author = {Hu, Linmei and Zhao, Ziwang and Ge, Xinkai and Song, Xuemeng and Nie, Liqiang},
	year = {2022},
	pages = {null},
}

@article{ma_kapalm_2023,
	title = {{KAPALM}: {Knowledge} {grAPh} {enhAnced} {Language} {Models} for {Fake} {News} {Detection}},
	url = {https://www.semanticscholar.org/paper/5b3c5542d3e9f955e492598839d32cc9889f1e32},
	doi = {10.18653/v1/2023.findings-emnlp.263},
	abstract = {,},
	author = {Ma, Jing and Chen, Chen and Hou, Chunyan and Yuan, Xiao-hui},
	year = {2023},
}

@article{_research_2024,
	title = {Research on {Fake} {News} {Detection} {Method} {Using} {Heterogeneous} {Graph} {Fusion} with {Background} {Knowledge}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/49f788b9d59ef0a60426ada6a48aa1f1a3022379},
	doi = {10.12677/csa.2024.143068},
	abstract = {Nowadays, the task of fake news detection is receiving more and more attention. This article takes},
	journal = {Computer Science and Application},
	author = {何, 迈},
	year = {2024},
	pages = {null},
}

@article{wei_uncertainty-aware_2022,
	title = {Uncertainty-aware {Propagation} {Structure} {Reconstruction} for {Fake} {News} {Detection}},
	url = {https://www.semanticscholar.org/paper/df0ee21feb9fc7045f83cefbd68740f87af6dcfa},
	abstract = {The widespread of fake news has detrimental societal effects. Recent works model information propagation as graph structure and aggregate structural features from user interactions for fake news detection. However, they usually neglect a broader propagation uncertainty issue, caused by some missing and unreliable interactions during actual spreading, and suffer from learning accurate and diverse structural properties. In this paper, we propose a novel dual graph-based model, Uncertainty-aware Propagation Structure Reconstruction (UPSR) for improving fake news detection. Specifically, after the original propagation modeling, we introduce propagation structure reconstruction to fully explore latent interactions in the actual propagation. We design a novel Gaussian Propagation Estimation to refine the original deterministic node representation by multiple Gaussian distributions and arise latent interactions with KL divergence between distributions in a multi-facet manner. Extensive experiments on two real-world datasets demonstrate the effectiveness and superiority of our model.},
	author = {Wei, Lingwei and Hu, Dou and Zhou, Wei and Hu, Songlin},
	year = {2022},
}

@article{meyers_fake_2020,
	title = {Fake {News} {Detection} on {Twitter} {Using} {Propagation} {Structures}},
	url = {https://www.semanticscholar.org/paper/e2e5f51f279f68441e4e69692562bec7ace66f13},
	doi = {10.1007/978-3-030-61841-4_10},
	abstract = {S2 TL;DR: It is shown that real news are significantly bigger in size, are spread by users with more followers and less followings, and are actively spread on Twitter for a longer period of time than fake news.},
	author = {Meyers, Marion and Weiss, Gerhard and Spanakis, Gerasimos},
	year = {2020},
}
